# -*- coding: utf-8 -*-
"""nm sucessfull.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vz1zCHM-weav12IzsOMIp9S1xeev1wPY
"""

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import pandas as pd
import matplotlib.pyplot as plt

# ---------------- Model Setup ---------------- #
model_name = "ibm-granite/granite-3.2-2b-instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Ensure proper device handling
device = "cuda" if torch.cuda.is_available() else "cpu"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if device == "cuda" else torch.float32,
).to(device)

# Ensure pad token exists
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

# ---------------- Utility Functions ---------------- #
def generate_response(prompt, max_length=512):
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512).to(device)
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_length=max_length,
            temperature=0.7,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    if response.startswith(prompt):
        response = response[len(prompt):].strip()
    return response

# ---------------- Features ---------------- #

def disease_prediction(symptoms):
    prompt = (
        f"Based on the following symptoms, provide possible medical conditions and general medication suggestions. "
        f"Always emphasize the importance of consulting a doctor.\n\nSymptoms: {symptoms}\n\n"
        f"Analysis (Informational only):"
    )
    return generate_response(prompt, max_length=800)


def treatment_plan(condition, age, gender, medical_history):
    prompt = (
        f"Generate personalized treatment suggestions.\n\n"
        f"Medical Condition: {condition}\nAge: {age}\nGender: {gender}\nMedical History: {medical_history}\n\n"
        f"Treatment Plan (Informational only):"
    )
    return generate_response(prompt, max_length=800)

# Chatbot memory
chat_history = []
def patient_chat(message, history):
    history = history or []
    prompt = "Patient: " + message + "\nAssistant:"  # simple chat format
    response = generate_response(prompt, max_length=300)
    history.append((message, response))
    return history, history

# Health analytics mock data
def health_dashboard():
    data = {
        "Metric": ["Blood Pressure", "Heart Rate", "Blood Sugar", "Cholesterol"],
        "Value": [120, 75, 95, 180]
    }
    df = pd.DataFrame(data)

    # Create a bar chart
    fig, ax = plt.subplots()
    ax.bar(df["Metric"], df["Value"])
    ax.set_title("Patient Health Metrics")
    ax.set_ylabel("Values")

    return df, fig

# ---------------- Gradio UI ---------------- #
with gr.Blocks() as app:
    gr.Markdown("# ü©∫ Medical AI Assistant")
    gr.Markdown("‚ö†Ô∏è *Disclaimer:* Informational purposes only. Always consult healthcare professionals.")

    with gr.Tabs():
        # Tab 1: Disease Prediction
        with gr.Tab("Disease Prediction"):
            with gr.Row():
                with gr.Column():
                    symptoms_input = gr.Textbox(label="Enter Symptoms", placeholder="e.g., fever, cough, fatigue", lines=4)
                    predict_btn = gr.Button("Analyze Symptoms")
                with gr.Column():
                    prediction_output = gr.Textbox(label="Possible Conditions & Recommendations", lines=20)
            predict_btn.click(disease_prediction, inputs=symptoms_input, outputs=prediction_output)

        # Tab 2: Treatment Plan
        with gr.Tab("Treatment Plans"):
            with gr.Row():
                with gr.Column():
                    condition_input = gr.Textbox(label="Medical Condition", placeholder="e.g., diabetes, hypertension")
                    age_input = gr.Number(label="Age", value=30)
                    gender_input = gr.Dropdown(["Male", "Female", "Other"], label="Gender", value="Male")
                    history_input = gr.Textbox(label="Medical History", placeholder="Allergies, medications...", lines=3)
                    plan_btn = gr.Button("Generate Treatment Plan")
                with gr.Column():
                    plan_output = gr.Textbox(label="Personalized Treatment Plan", lines=20)
            plan_btn.click(treatment_plan, inputs=[condition_input, age_input, gender_input, history_input], outputs=plan_output)

        # Tab 3: Patient Chat
        with gr.Tab("Patient Chat"):
            chatbot = gr.Chatbot(label="Chat with Medical Assistant")
            msg = gr.Textbox(label="Type your message")
            clear = gr.Button("Analysis Chat")

            msg.submit(patient_chat, [msg, chatbot], [chatbot, chatbot])
            clear.click(lambda: None, None, chatbot, queue=False)

        # Tab 4: Health Analytics Dashboard
        with gr.Tab("Health Analytics Dashboard"):
            df_output = gr.DataFrame(headers=["Metric", "Value"], label="Patient Health Data")
            plot_output = gr.Plot(label="Health Chart")
            load_btn = gr.Button("Load Health Analytics")
            load_btn.click(health_dashboard, inputs=None, outputs=[df_output, plot_output])

# ---------------- Run App ---------------- #
app.launch(share=True)